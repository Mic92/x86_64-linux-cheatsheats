-   Index
-   May 2019



VCVTQQ2PS — CONVERT PACKED QUADWORD INTEGERS TO PACKED SINGLE-PRECISION FLOATING-POINT VALUES


  Opcode/Instruction                                                   Op/En   64/32 bit Mode Support   CPUID Feature Flag   Description
  -------------------------------------------------------------------- ------- ------------------------ -------------------- ----------------------------------------------------------------------------------------------------------------------------------------
  EVEX.128.0F.W1 5B /r VCVTQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst       A       V/V                      AVX512VL AVX512DQ    Convert two packed quadword integers from xmm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.
  EVEX.256.0F.W1 5B /r VCVTQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst       A       V/V                      AVX512VL AVX512DQ    Convert four packed quadword integers from ymm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.
  EVEX.512.0F.W1 5B /r VCVTQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}   A       V/V                      AVX512DQ             Convert eight packed quadword integers from zmm2/mem to eight packed single-precision floating-point values in ymm1 with writemask k1.


Instruction Operand Encoding ¶

  ------- ------------ --------------- --------------- ----------- -----------
  Op/En   Tuple Type   Operand 1       Operand 2       Operand 3   Operand 4
  A       Full         ModRM:reg (w)   ModRM:r/m (r)   NA          NA
  ------- ------------ --------------- --------------- ----------- -----------

Description ¶

Converts packed quadword integers in the source operand (second operand)
to packed single-precision floating-point values in the destination
operand (first operand).

The source operand is a ZMM/YMM/XMM register or a 512/256/128-bit memory
location. The destination operation is a YMM/XMM/XMM (lower 64 bits)
register conditionally updated with writemask k1.

EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.

Operation ¶

VCVTQQ2PS (EVEX encoded versions) when src operand is a register ¶

    (KL, VL) = (2, 128), (4, 256), (8, 512)
    FOR j←0 TO KL-1
        i←j * 64
        k←j * 32
        IF k1[j] OR *no writemask*
            THEN DEST[k+31:k]←
                Convert_QuadInteger_To_Single_Precision_Floating_Point(SRC[i+63:i])
            ELSE
                IF *merging-masking* ; merging-masking
                    THEN *DEST[k+31:k] remains unchanged*
                    ELSE ; zeroing-masking
                        DEST[k+31:k] ← 0
                FI
        FI;
    ENDFOR
    DEST[MAXVL-1:VL/2] ← 0

VCVTQQ2PS (EVEX encoded versions) when src operand is a memory source ¶

    (KL, VL) = (2, 128), (4, 256), (8, 512)
    FOR j←0 TO KL-1
        i←j * 64
        k←j * 32
        IF k1[j] OR *no writemask*
            THEN
                IF (EVEX.b == 1)
                    THEN
                        DEST[k+31:k] ←
                Convert_QuadInteger_To_Single_Precision_Floating_Point(SRC[63:0])
                    ELSE
                        DEST[k+31:k] ←
                Convert_QuadInteger_To_Single_Precision_Floating_Point(SRC[i+63:i])
                FI;
            ELSE
                IF *merging-masking* ; merging-masking
                    THEN *DEST[k+31:k] remains unchanged*
                    ELSE ; zeroing-masking
                        DEST[k+31:k] ← 0
                FI
        FI;
    ENDFOR
    DEST[MAXVL-1:VL/2] ← 0

Intel C/C++ Compiler Intrinsic Equivalent ¶

    VCVTQQ2PS __m256 _mm512_cvtepi64_ps( __m512i a);

    VCVTQQ2PS __m256 _mm512_mask_cvtepi64_ps( __m256 s, __mmask16 k, __m512i a);

    VCVTQQ2PS __m256 _mm512_maskz_cvtepi64_ps( __mmask16 k, __m512i a);

    VCVTQQ2PS __m256 _mm512_cvt_roundepi64_ps( __m512i a, int r);

    VCVTQQ2PS __m256 _mm512_mask_cvt_roundepi_ps( __m256 s, __mmask8 k, __m512i a, int r);

    VCVTQQ2PS __m256 _mm512_maskz_cvt_roundepi64_ps( __mmask8 k, __m512i a, int r);

    VCVTQQ2PS __m128 _mm256_cvtepi64_ps( __m256i a);

    VCVTQQ2PS __m128 _mm256_mask_cvtepi64_ps( __m128 s, __mmask8 k, __m256i a);

    VCVTQQ2PS __m128 _mm256_maskz_cvtepi64_ps( __mmask8 k, __m256i a);

    VCVTQQ2PS __m128 _mm_cvtepi64_ps( __m128i a);

    VCVTQQ2PS __m128 _mm_mask_cvtepi64_ps( __m128 s, __mmask8 k, __m128i a);

    VCVTQQ2PS __m128 _mm_maskz_cvtepi64_ps( __mmask8 k, __m128i a);

SIMD Floating-Point Exceptions ¶

Precision

Other Exceptions ¶

EVEX-encoded instructions, see Exceptions Type E2

  ----- ------------------------
  #UD   If EVEX.vvvv != 1111B.
  ----- ------------------------

This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be incomplete or b_(r)oke_(n) in
various obvious or non-obvious ways. Refer to Intel® 64 and IA-32
Architectures Software Developer’s Manual for anything serious.
