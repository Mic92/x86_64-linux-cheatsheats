-   Index
-   May 2019

UNPCKLPS — Unpack and Interleave Low Packed Single-Precision Floating-Point Values

  Opcode/Instruction                                                     Op/En   64/32 bit Mode Support   CPUID Feature Flag   Description
  ---------------------------------------------------------------------- ------- ------------------------ -------------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------
  NP 0F 14 /r UNPCKLPS xmm1, xmm2/m128                                   A       V/V                      SSE                  Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/m128.
  VEX.128.0F.WIG 14 /r VUNPCKLPS xmm1,xmm2, xmm3/m128                    B       V/V                      AVX                  Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/m128.
  VEX.256.0F.WIG 14 /r VUNPCKLPS ymm1,ymm2,ymm3/m256                     B       V/V                      AVX                  Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/m256.
  EVEX.128.0F.W0 14 /r VUNPCKLPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst   C       V/V                      AVX512VL AVX512F     Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/mem and write result to xmm1 subject to write mask k1.
  EVEX.256.0F.W0 14 /r VUNPCKLPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst   C       V/V                      AVX512VL AVX512F     Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/mem and write result to ymm1 subject to write mask k1.
  EVEX.512.0F.W0 14 /r VUNPCKLPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst   C       V/V                      AVX512F              Unpacks and Interleaves single-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to write mask k1.

Instruction Operand Encoding ¶

  ------- ------------ ------------------ --------------- --------------- -----------
  Op/En   Tuple Type   Operand 1          Operand 2       Operand 3       Operand 4
  A       NA           ModRM:reg (r, w)   ModRM:r/m (r)   NA              NA
  B       NA           ModRM:reg (w)      VEX.vvvv (r)    ModRM:r/m (r)   NA
  C       Full         ModRM:reg (w)      EVEX.vvvv (r)   ModRM:r/m (r)   NA
  ------- ------------ ------------------ --------------- --------------- -----------

Description ¶

Performs an interleaved unpack of the low single-precision
floating-point values from the first source operand and the second
source operand.

128-bit Legacy SSE version: The second source can be an XMM register or
an 128-bit memory location. The destination is not distinct from the
first source XMM register and the upper bits (MAXVL-1:128) of the
corresponding ZMM register destination are unmodified. When unpacking
from a memory operand, an implementation may fetch only the appropriate
64 bits; however, alignment to 16-byte boundary and normal segment
checking will still be enforced.

VEX.128 encoded version: The first source operand is a XMM register. The
second source operand can be a XMM register or a 128-bit memory
location. The destination operand is a XMM register. The upper bits
(MAXVL-1:128) of the corresponding ZMM register destination are zeroed.

VEX.256 encoded version: The first source operand is a YMM register. The
second source operand can be a YMM register or a 256-bit memory
location. The destination operand is a YMM register.

[]

Figure 4-28. VUNPCKLPS Operation

EVEX.512 encoded version: The first source operand is a ZMM register.
The second source operand is a ZMM register, a 512-bit memory location,
or a 512-bit vector broadcasted from a 32-bit memory location. The
destination operand is a ZMM register, conditionally updated using
writemask k1.

EVEX.256 encoded version: The first source operand is a YMM register.
The second source operand is a YMM register, a 256-bit memory location,
or a 256-bit vector broadcasted from a 32-bit memory location. The
destination operand is a YMM register, conditionally updated using
writemask k1.

EVEX.128 encoded version: The first source operand is an XMM register.
The second source operand is a XMM register, a 128-bit memory location,
or a 128-bit vector broadcasted from a 32-bit memory location. The
destination operand is a XMM register, conditionally updated using
writemask k1.

Operation ¶

VUNPCKLPS (EVEX encoded version when SRC2 is a ZMM register) ¶

    (KL, VL) = (4, 128), (8, 256), (16, 512)
    IF VL >= 128
        TMP_DEST[31:0] ← SRC1[31:0]
        TMP_DEST[63:32] ← SRC2[31:0]
        TMP_DEST[95:64] ← SRC1[63:32]
        TMP_DEST[127:96] ← SRC2[63:32]
    FI;
    IF VL >= 256
        TMP_DEST[159:128] ← SRC1[159:128]
        TMP_DEST[191:160] ← SRC2[159:128]
        TMP_DEST[223:192] ← SRC1[191:160]
        TMP_DEST[255:224] ← SRC2[191:160]
    FI;
    IF VL >= 512
        TMP_DEST[287:256] ← SRC1[287:256]
        TMP_DEST[319:288] ← SRC2[287:256]
        TMP_DEST[351:320] ← SRC1[319:288]
        TMP_DEST[383:352] ← SRC2[319:288]
        TMP_DEST[415:384] ← SRC1[415:384]
        TMP_DEST[447:416] ← SRC2[415:384]
        TMP_DEST[479:448] ← SRC1[447:416]
        TMP_DEST[511:480] ← SRC2[447:416]
    FI;
    FOR j←0 TO KL-1
        i←j * 32
        IF k1[j] OR *no writemask*
            THEN DEST[i+31:i]←TMP_DEST[i+31:i]
            ELSE
                IF *merging-masking* ; merging-masking
                    THEN *DEST[i+31:i] remains unchanged*
                    ELSE *zeroing-masking*
                            ; zeroing-masking
                        DEST[i+31:i] ← 0
                FI
        FI;
    ENDFOR
    DEST[MAXVL-1:VL] ← 0

VUNPCKLPS (EVEX encoded version when SRC2 is memory) ¶

    (KL, VL) = (4, 128), (8, 256), (16, 512)
    FOR j←0 TO KL-1
        i←j * 31
        IF (EVEX.b = 1)
            THEN TMP_SRC2[i+31:i]←SRC2[31:0]
            ELSE TMP_SRC2[i+31:i]←SRC2[i+31:i]
        FI;
    ENDFOR;
    IF VL >= 128
    TMP_DEST[31:0] ← SRC1[31:0]
    TMP_DEST[63:32] ← TMP_SRC2[31:0]
    TMP_DEST[95:64] ← SRC1[63:32]
    TMP_DEST[127:96] ← TMP_SRC2[63:32]
    FI;
    IF VL >= 256
        TMP_DEST[159:128] ← SRC1[159:128]
        TMP_DEST[191:160] ← TMP_SRC2[159:128]
        TMP_DEST[223:192] ← SRC1[191:160]
        TMP_DEST[255:224] ← TMP_SRC2[191:160]
    FI;
    IF VL >= 512
        TMP_DEST[287:256] ← SRC1[287:256]
        TMP_DEST[319:288] ← TMP_SRC2[287:256]
        TMP_DEST[351:320] ← SRC1[319:288]
        TMP_DEST[383:352] ← TMP_SRC2[319:288]
        TMP_DEST[415:384] ← SRC1[415:384]
        TMP_DEST[447:416] ← TMP_SRC2[415:384]
        TMP_DEST[479:448] ← SRC1[447:416]
        TMP_DEST[511:480] ← TMP_SRC2[447:416]
    FI;
    FOR j←0 TO KL-1
        i←j * 32
        IF k1[j] OR *no writemask*
            THEN DEST[i+31:i]←TMP_DEST[i+31:i]
            ELSE
                IF *merging-masking*
                            ; merging-masking
                    THEN *DEST[i+31:i] remains unchanged*
                    ELSE *zeroing-masking*
                                ; zeroing-masking
                        DEST[i+31:i] ← 0
                FI
        FI;
    ENDFOR
    DEST[MAXVL-1:VL] ← 0

UNPCKLPS (VEX.256 encoded version) ¶

    DEST[31:0] ←SRC1[31:0]
    DEST[63:32] ←SRC2[31:0]
    DEST[95:64] ←SRC1[63:32]
    DEST[127:96] ←SRC2[63:32]
    DEST[159:128] ←SRC1[159:128]
    DEST[191:160] ←SRC2[159:128]
    DEST[223:192] ←SRC1[191:160]
    DEST[255:224] ←SRC2[191:160]
    DEST[MAXVL-1:256] ← 0

VUNPCKLPS (VEX.128 encoded version) ¶

    DEST[31:0] ←SRC1[31:0]
    DEST[63:32] ←SRC2[31:0]
    DEST[95:64] ←SRC1[63:32]
    DEST[127:96] ←SRC2[63:32]
    DEST[MAXVL-1:128] ←0

UNPCKLPS (128-bit Legacy SSE version) ¶

    DEST[31:0] ←SRC1[31:0]
    DEST[63:32] ←SRC2[31:0]
    DEST[95:64] ←SRC1[63:32]
    DEST[127:96] ←SRC2[63:32]
    DEST[MAXVL-1:128] (Unmodified)

Intel C/C++ Compiler Intrinsic Equivalent ¶

    VUNPCKLPS __m512 _mm512_unpacklo_ps(__m512 a, __m512 b);

    VUNPCKLPS __m512 _mm512_mask_unpacklo_ps(__m512 s, __mmask16 k, __m512 a, __m512 b);

    VUNPCKLPS __m512 _mm512_maskz_unpacklo_ps(__mmask16 k, __m512 a, __m512 b);

    VUNPCKLPS __m256 _mm256_unpacklo_ps (__m256 a, __m256 b);

    VUNPCKLPS __m256 _mm256_mask_unpacklo_ps(__m256 s, __mmask8 k, __m256 a, __m256 b);

    VUNPCKLPS __m256 _mm256_maskz_unpacklo_ps(__mmask8 k, __m256 a, __m256 b);

    UNPCKLPS __m128 _mm_unpacklo_ps (__m128 a, __m128 b);

    VUNPCKLPS __m128 _mm_mask_unpacklo_ps(__m128 s, __mmask8 k, __m128 a, __m128 b);

    VUNPCKLPS __m128 _mm_maskz_unpacklo_ps(__mmask8 k, __m128 a, __m128 b);

SIMD Floating-Point Exceptions ¶

None

Other Exceptions ¶

Non-EVEX-encoded instructions, see Exceptions Type 4.

EVEX-encoded instructions, see Exceptions Type E4NF.

This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be incomplete or b_(r)oke_(n) in
various obvious or non-obvious ways. Refer to Intel® 64 and IA-32
Architectures Software Developer’s Manual for anything serious.
