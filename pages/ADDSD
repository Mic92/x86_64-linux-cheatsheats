-   Index
-   December 2017



ADDSD — ADD SCALAR DOUBLE-PRECISION FLOATING-POINT VALUES


  Opcode/Instruction                                                    Op/En   64/32 bit Mode Support   CPUID Feature Flag   Description
  --------------------------------------------------------------------- ------- ------------------------ -------------------- -------------------------------------------------------------------------------------------------------------------------
  F2 0F 58 /r ADDSD xmm1, xmm2/m64                                      A       V/V                      SSE2                 Add the low double-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1.
  VEX.NDS.LIG.F2.0F.WIG 58 /r VADDSD xmm1, xmm2, xmm3/m64               B       V/V                      AVX                  Add the low double-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.
  EVEX.NDS.LIG.F2.0F.W1 58 /r VADDSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}   C       V/V                      AVX512F              Add the low double-precision floating-point value from xmm3/m64 to xmm2 and store the result in xmm1 with writemask k1.


Instruction Operand Encoding¶

  ------- --------------- ------------------ --------------- --------------- -----------
  Op/En   Tuple Type      Operand 1          Operand 2       Operand 3       Operand 4
  A       NA              ModRM:reg (r, w)   ModRM:r/m (r)   NA              NA
  B       NA              ModRM:reg (w)      VEX.vvvv        ModRM:r/m (r)   NA
  C       Tuple1 Scalar   ModRM:reg (w)      EVEX.vvvv       ModRM:r/m (r)   NA
  ------- --------------- ------------------ --------------- --------------- -----------


Description¶

Adds the low double-precision floating-point values from the second
source operand and the first source operand and stores the
double-precision floating-point result in the destination operand.

The second source operand can be an XMM register or a 64-bit memory
location. The first source and destination operands are XMM registers.

128-bit Legacy SSE version: The first source and destination operands
are the same. Bits (MAXVL-1:64) of the corresponding destination
register remain unchanged.

EVEX and VEX.128 encoded version: The first source operand is encoded by
EVEX.vvvv/VEX.vvvv. Bits (127:64) of the XMM register destination are
copied from corresponding bits in the first source operand. Bits
(MAXVL-1:128) of the destination register are zeroed.

EVEX version: The low quadword element of the destination is updated
according to the writemask.

Software should ensure VADDSD is encoded with VEX.L=0. Encoding VADDSD
with VEX.L=1 may encounter unpredictable behavior across different
processor generations.


Operation¶

VADDSD (EVEX encoded version)¶

    IF (EVEX.b = 1) AND SRC2 *is a register*
        THEN
            SET_RM(EVEX.RC);
        ELSE
            SET_RM(MXCSR.RM);
    FI;
    IF k1[0] or *no writemask*
        THEN DEST[63:0]←SRC1[63:0] + SRC2[63:0]
        ELSE
            IF *merging-masking* ; merging-masking
                THEN *DEST[63:0] remains unchanged*
                ELSE ; zeroing-masking
                    THEN DEST[63:0]←0
            FI;
    FI;
    DEST[127:64] ← SRC1[127:64]
    DEST[MAXVL-1:128] ← 0

VADDSD (VEX.128 encoded version)¶

    DEST[63:0]←SRC1[63:0] + SRC2[63:0]
    DEST[127:64] ←SRC1[127:64]
    DEST[MAXVL-1:128] ←0

ADDSD (128-bit Legacy SSE version)¶

    DEST[63:0]←DEST[63:0] + SRC[63:0]
    DEST[MAXVL-1:64] (Unmodified)


Intel C/C++ Compiler Intrinsic Equivalent¶

    VADDSD __m128d _mm_mask_add_sd (__m128d s, __mmask8 k, __m128d a, __m128d b);

    VADDSD __m128d _mm_maskz_add_sd (__mmask8 k, __m128d a, __m128d b);

    VADDSD __m128d _mm_add_round_sd (__m128d a, __m128d b, int);

    VADDSD __m128d _mm_mask_add_round_sd (__m128d s, __mmask8 k, __m128d a, __m128d b, int);

    VADDSD __m128d _mm_maskz_add_round_sd (__mmask8 k, __m128d a, __m128d b, int);

    ADDSD __m128d _mm_add_sd (__m128d a, __m128d b);


SIMD Floating-Point Exceptions¶

Overflow, Underflow, Invalid, Precision, Denormal


Other Exceptions¶

VEX-encoded instruction, see Exceptions Type 3.

EVEX-encoded instruction, see Exceptions Type E3.

This UNOFFICIAL, mechanically-separated, non-verified reference is
provided for convenience, but it may be incomplete or b_(r)oke_(n) in
various obvious or non-obvious ways. Refer to Intel® 64 and IA-32
Architectures Software Developer’s Manual for anything serious.
